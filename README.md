# MLOps Platform - Production-Ready Customer Churn Prediction üöÄ

> **Complete MLOps Platform**: Production-grade machine learning system with experiment tracking, monitoring, and automated operations.

A comprehensive MLOps platform for customer churn prediction built with modern ML engineering practices. Includes MLflow for experiment tracking, Prometheus/Grafana for monitoring, automated backups, and production-hardened security.

## üéØ What's Included

This production-ready ML platform features:
- ‚úÖ Machine learning model training pipeline with MLflow tracking
- ‚úÖ REST API for model serving (FastAPI)
- ‚úÖ Automated testing and CI/CD (GitHub Actions)
- ‚úÖ Containerization with Docker and Kubernetes orchestration
- ‚úÖ Monitoring and observability (Prometheus + Grafana)
- ‚úÖ MLflow experiment tracking and model registry
- ‚úÖ Automated backup and disaster recovery
- ‚úÖ Production security hardening
- ‚úÖ Cloud deployment infrastructure (Terraform)

## üèóÔ∏è Architecture

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed system architecture.

**Key Components**:
- **API Layer**: FastAPI with prediction endpoints and health checks
- **ML Platform**: MLflow for experiment tracking and model registry
- **Storage**: PostgreSQL for metadata, PVCs for artifacts
- **Monitoring**: Prometheus metrics + Grafana dashboards + Alertmanager
- **Security**: Kubernetes RBAC, network policies, secrets management
- **Backup**: Automated daily backups to S3 with restore procedures

## üìö Learning Path

### ‚úÖ Phase 0: Project Setup (Current)
**Status**: In Progress  
**What we'll do**:
- [x] Initialize repository
- [ ] Create basic project structure
- [ ] Set up Python virtual environment
- [ ] Install initial dependencies

**Time**: 30 minutes

---

### üì¶ Phase 1: Basic ML Model
**What you'll learn**: Core ML fundamentals, scikit-learn basics  
**What we'll build**:
- Simple customer churn dataset generator
- Train a basic Random Forest model
- Save and load models with joblib
- Basic command-line training script

**Files to create**: `src/train_simple.py`, `src/model_simple.py`

---

### üîÑ Phase 2: Data Pipeline
**What you'll learn**: Data preprocessing, feature engineering  
**What we'll build**:
- Data preprocessing functions
- Feature scaling and encoding
- Data validation checks
- Separate training and preprocessing logic

**Files to create**: `src/preprocessing.py`, `src/data_validation.py`

---

### üéØ Phase 3: Enhanced Model Training
**What you'll learn**: Model evaluation, hyperparameter tuning  
**What we'll build**:
- Multiple model types (Random Forest, Gradient Boosting)
- Comprehensive evaluation metrics
- Model comparison
- Training configuration

**Files to create**: `src/model.py`, `src/train.py`, `config/config.yaml`

---

### üåê Phase 4: REST API
**What you'll learn**: FastAPI, API design, validation  
**What we'll build**:
- FastAPI application
- Prediction endpoint
- Input validation with Pydantic
- Auto-generated API docs
- Health check endpoint

**Files to create**: `src/api.py`, `src/schemas.py`

---

### üß™ Phase 5: Testing
**What you'll learn**: Unit testing, pytest, test-driven development  
**What we'll build**:
- Unit tests for all components
- Test fixtures
## üöÄ Quick Start

### Prerequisites
- Python 3.9+
- Docker and Docker Compose
- kubectl (for Kubernetes deployment)
- AWS CLI (for cloud deployment)

### Local Development

```bash
# Clone repository
git clone https://github.com/squirke1/llm-mlops-platform.git
cd llm-mlops-platform

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r requirements.txt

# Train model
python src/train.py

# Run API locally
uvicorn api.app:app --reload

# Run tests
pytest tests/ -v

# Start with Docker Compose
docker-compose up
```

### Production Deployment

See [docs/PRODUCTION_DEPLOYMENT.md](docs/PRODUCTION_DEPLOYMENT.md) for complete production deployment guide.

## üõ†Ô∏è Tech Stack

- **Languages**: Python 3.9
- **ML Framework**: Scikit-learn 1.3.2
- **API Framework**: FastAPI 0.104.1
- **Experiment Tracking**: MLflow 2.9.2
- **Database**: PostgreSQL 15
- **Monitoring**: Prometheus 2.45 + Grafana 10.0
- **Testing**: Pytest 7.4.3
- **Containerization**: Docker + Docker Compose
- **Orchestration**: Kubernetes 1.24+
- **CI/CD**: GitHub Actions
- **Infrastructure**: Terraform (AWS EKS)

## üìä Development Phases

### ‚úÖ Phase 1-6: Core ML Pipeline (Completed)
- ML model training and evaluation
- REST API with FastAPI
- Comprehensive testing
- Docker containerization

### ‚úÖ Phase 7: CI/CD (Completed)
- Automated testing pipeline
- Code quality checks (black, isort, flake8)
- Docker image building
- Kubernetes manifest validation
- Terraform validation

### ‚úÖ Phase 8: Monitoring (Completed)
- Prometheus metrics collection
- Grafana dashboards
- Custom application metrics
- Alert rules
- API instrumentation

### ‚úÖ Phase 9: MLflow Integration (Completed)
- Experiment tracking
- Model registry with versioning
- Model stage management (Production/Staging)
- Artifact storage
- API integration with model registry

### ‚úÖ Phase 10: Production Hardening (Completed)
- **Secrets Management**: Kubernetes secrets + AWS Secrets Manager integration
- **Security Hardening**: RBAC, network policies, pod security policies
- **Backup & DR**: Automated daily backups to S3, restore procedures
- **Monitoring & Alerts**: Comprehensive alerting rules and runbooks
- **Documentation**: Production deployment guide, architecture docs, runbooks

## üìÅ Project Structure

```
llm-mlops-platform/
‚îú‚îÄ‚îÄ api/                        # FastAPI application
‚îÇ   ‚îî‚îÄ‚îÄ app.py                 # API endpoints and model serving
‚îú‚îÄ‚îÄ src/                       # Source code
‚îÇ   ‚îú‚îÄ‚îÄ data.py               # Data generation
‚îÇ   ‚îú‚îÄ‚îÄ model.py              # Model training logic
‚îÇ   ‚îú‚îÄ‚îÄ train.py              # Training script with MLflow
‚îÇ   ‚îî‚îÄ‚îÄ mlflow_utils.py       # MLflow utilities
‚îú‚îÄ‚îÄ tests/                     # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py           # API tests
‚îÇ   ‚îú‚îÄ‚îÄ test_model.py         # Model tests
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py           # Test fixtures
‚îú‚îÄ‚îÄ k8s/                       # Kubernetes manifests
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml       # API deployment
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml          # API service
‚îÇ   ‚îî‚îÄ‚îÄ namespace.yaml        # Namespace definition
‚îú‚îÄ‚îÄ mlflow/                    # MLflow configuration
‚îÇ   ‚îú‚îÄ‚îÄ mlflow-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ postgres-deployment.yaml
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ monitoring/                # Monitoring setup
‚îÇ   ‚îú‚îÄ‚îÄ prometheus-config.yaml
‚îÇ   ‚îú‚îÄ‚îÄ prometheus-alerts.yaml
‚îÇ   ‚îú‚îÄ‚îÄ grafana-dashboards.yaml
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ security/                  # Security configurations
‚îÇ   ‚îú‚îÄ‚îÄ rbac.yaml             # Role-based access control
‚îÇ   ‚îú‚îÄ‚îÄ network-policies.yaml # Network segmentation
‚îÇ   ‚îú‚îÄ‚îÄ pod-security-policy.yaml
‚îÇ   ‚îî‚îÄ‚îÄ resource-quotas.yaml
‚îú‚îÄ‚îÄ secrets/                   # Secrets management
‚îÇ   ‚îú‚îÄ‚îÄ secrets.yaml          # Templates (not actual secrets)
‚îÇ   ‚îú‚îÄ‚îÄ aws-secret-provider.yaml
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ backup/                    # Backup and DR
‚îÇ   ‚îú‚îÄ‚îÄ backup-cronjobs.yaml  # Automated backup jobs
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ runbooks/                  # Operational runbooks
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # Incident response procedures
‚îú‚îÄ‚îÄ docs/                      # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md       # System architecture
‚îÇ   ‚îî‚îÄ‚îÄ PRODUCTION_DEPLOYMENT.md
‚îú‚îÄ‚îÄ .github/workflows/         # CI/CD pipelines
‚îÇ   ‚îî‚îÄ‚îÄ ci.yml
‚îú‚îÄ‚îÄ Dockerfile                 # Container image
‚îú‚îÄ‚îÄ docker-compose.yml         # Local development
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îî‚îÄ‚îÄ README.md                  # This file
```

## üìñ Documentation

- **[Architecture](docs/ARCHITECTURE.md)**: System design and component details
- **[Production Deployment](docs/PRODUCTION_DEPLOYMENT.md)**: Complete deployment guide
- **[Runbooks](runbooks/README.md)**: Operational procedures and troubleshooting
- **[MLflow Guide](mlflow/README.md)**: Experiment tracking and model registry
- **[Monitoring Guide](monitoring/README.md)**: Metrics and alerting
- **[Backup Guide](backup/README.md)**: Backup and disaster recovery
- **[Secrets Management](secrets/README.md)**: Security and secrets handling

## üîç API Endpoints

### Prediction Endpoints
- `POST /predict` - Single prediction
- `POST /predict/batch` - Batch predictions

### Health & Monitoring
- `GET /health` - Health check
- `GET /metrics` - Prometheus metrics

### API Documentation
- `GET /docs` - Interactive API documentation (Swagger UI)
- `GET /redoc` - Alternative API documentation

## üß™ Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov=api --cov-report=html

# Run specific test file
pytest tests/test_api.py -v

# Run with specific markers
pytest tests/ -m "not slow" -v
```

## üìà Monitoring

### Metrics Available
- HTTP request rates and latencies
- Prediction counts and results
- Model confidence scores
- Resource usage (CPU, memory)
- Business metrics (churn rate)

### Access Monitoring

```bash
# Port-forward Prometheus
kubectl port-forward svc/prometheus 9090:9090 -n mlops-platform

# Port-forward Grafana
kubectl port-forward svc/grafana 3000:3000 -n mlops-platform
# Default credentials: admin / (see secret)
```

## üîê Security

### Features
- Kubernetes RBAC for access control
- Network policies for pod isolation
- Pod security policies
- Secrets management (K8s secrets / AWS Secrets Manager)
- TLS/SSL for all external traffic
- Resource quotas and limits
- Automated security scanning in CI

### Best Practices
- No secrets in Git
- Principle of least privilege
- Regular secret rotation
- Encrypted backups
- Audit logging enabled

## üíæ Backup & Recovery

### Automated Backups
- **PostgreSQL**: Daily at 2 AM UTC
- **MLflow Artifacts**: Daily at 3 AM UTC
- **Retention**: 7 days local, 90 days in S3

### Disaster Recovery
- RTO: 4 hours
- RPO: 24 hours
- Quarterly DR drills
- Documented restore procedures

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Workflow
- All PRs require passing CI checks
- Code coverage must be maintained (>80%)
- Follow existing code style (black, isort, flake8)
- Update documentation as needed

## üìù Status

**All phases completed!** ‚úÖ

This is a fully functional, production-ready MLOps platform with:
- Complete ML pipeline from training to serving
- Experiment tracking and model versioning with MLflow
- Comprehensive monitoring and alerting
- Production-grade security and backup solutions
- Full documentation and operational runbooks

Ready for deployment to production environments.

## üìß Contact

- **Author**: Stephen Quirke
- **Repository**: [github.com/squirke1/llm-mlops-platform](https://github.com/squirke1/llm-mlops-platform)
- **Issues**: [GitHub Issues](https://github.com/squirke1/llm-mlops-platform/issues)

## üìÑ License

**Phase 0**: Setting up the project foundation

**Next Steps**:
1. Create basic directory structure
2. Set up Python virtual environment
3. Install scikit-learn and pandas
4. Ready for Phase 1!

---

**Repository**: [llm-mlops-platform](https://github.com/squirke1/llm-mlops-platform)  
**Author**: Stephen Quirke  
**Purpose**: Educational MLOps showcase built incrementally
